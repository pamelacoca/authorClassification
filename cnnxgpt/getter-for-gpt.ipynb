{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import datasetgenerator as dsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR1 = \"coutinho-dataset\"\n",
    "AUTHOR2 = \"denser-dataset\"\n",
    "PATH_TO_RAW_DATA = \"data/raw/\"\n",
    "PATH_TO_PARSED_DATA = \"data/parsed/\"\n",
    "\n",
    "ds_gen = dsg.ds_gen(is_gpt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614\n"
     ]
    }
   ],
   "source": [
    "len_data = ds_gen.get_data_length(dsg.ds_gen.DENSER, go_up_on_path=1)\n",
    "print(len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraph_size_list(paragraph_set):\n",
    "    paragraph_sizes = []\n",
    "    for paragraph in paragraph_set:\n",
    "        paragraph_size = len(paragraph)\n",
    "        paragraph_sizes.append(paragraph_size)\n",
    "    return paragraph_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_1, test_dataset_1 = ds_gen.get_dataset_from_author(dsg.ds_gen.COUTINHO, 0.8, 20, go_up_on_path=1)\n",
    "train_dataset_2, test_dataset_2 = ds_gen.get_dataset_from_author(dsg.ds_gen.DENSER, 0.8, 20, go_up_on_path=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt_1_sizes = get_paragraph_size_list(train_dataset_1)\n",
    "train_dt_2_sizes = get_paragraph_size_list(train_dataset_2)\n",
    "test_dt_1_sizes = get_paragraph_size_list(test_dataset_1)\n",
    "test_dt_2_sizes = get_paragraph_size_list(test_dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data, rule):\n",
    "    while (len(data) < rule):\n",
    "        data = data + \" 0\"\n",
    "\n",
    "    if(len(data) > rule):\n",
    "        data = data[0:rule]\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_paragraph_set(paragraph_set):\n",
    "    cut_paragraph_set= []\n",
    "    for paragraph in paragraph_set:\n",
    "        cut_paragraph = normalize_data(paragraph, 520)\n",
    "        print(cut_paragraph)\n",
    "        cut_paragraph_set.append(cut_paragraph)\n",
    "    print(len(cut_paragraph_set))\n",
    "    return cut_paragraph_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Set de treino 1\")\n",
    "cut_paragraph_set(train_dataset_1)\n",
    "print(\"\\n Set de treino 2\")\n",
    "cut_paragraph_set(train_dataset_2)\n",
    "print(\"\\n Set de teste 1\")\n",
    "cut_paragraph_set(test_dataset_1)\n",
    "print(\"\\n Set de teste 2\")\n",
    "cut_paragraph_set(test_dataset_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
